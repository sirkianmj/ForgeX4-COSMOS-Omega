{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "962f6c8f",
   "metadata": {},
   "source": [
    "# Digital Twin v4.0: Deep Stacking Ensemble\n",
    "\n",
    "**Author:** Kian Mansouri Jamshidi\n",
    "**Project Director:** Kian Mansouri Jamshidi\n",
    "**Date:** 2025-09-27\n",
    "\n",
    "## Objective\n",
    "This is the final and most powerful modeling architecture of Sprint 5. We will construct a deep, multi-layered hierarchical ensemble as designed by the Project Director. This 'network of AIs' features three distinct base models, a second layer of three diverse meta-models, and a final unifying 'Superior AI' model. This is the ultimate attempt to achieve the highest possible R² score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bff985",
   "metadata": {},
   "source": [
    "### 1. Imports and Full Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b2e1034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded.\n",
      "Layer 1 Base Models loaded.\n",
      "Data aligned. Final dataset size: 6899 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "# --- Load Data & Models ---\n",
    "PROJECT_ROOT = Path('.').resolve().parent\n",
    "TELEMETRY_DIR = PROJECT_ROOT / 'data' / 'telemetry_v2'\n",
    "ARTIFACT_DIR = PROJECT_ROOT / 'artifacts' / 'phase2'\n",
    "df_list = [pd.read_parquet(file) for file in glob.glob(str(TELEMETRY_DIR / \"*.parquet\"))]\n",
    "df = pd.concat(df_list, ignore_index=True).sort_values(by='timestamp').reset_index(drop=True)\n",
    "if 'cpu_temp_celsius_avg' in df.columns:\n",
    "    df = df.drop('cpu_temp_celsius_avg', axis=1)\n",
    "print(\"Data loaded.\")\n",
    "\n",
    "model_v2_0 = joblib.load(ARTIFACT_DIR / 'digital_twin_v2.0.joblib')\n",
    "model_v2_1 = joblib.load(ARTIFACT_DIR / 'digital_twin_v2.1_tuned.joblib')\n",
    "model_v2_3 = joblib.load(ARTIFACT_DIR / 'digital_twin_v2.3_deep.joblib')\n",
    "print(\"Layer 1 Base Models loaded.\")\n",
    "\n",
    "# --- Feature Engineering Functions ---\n",
    "def create_v2_0_features(df):\n",
    "    df_f=df.copy();workload_dummies=pd.get_dummies(df_f['workload_type'],prefix='workload');df_f=pd.concat([df_f,workload_dummies],axis=1);df_f['overall_util_rolling_mean']=df_f['cpu_util_overall'].rolling(window=10).mean();df_f['overall_util_rolling_std']=df_f['cpu_util_overall'].rolling(window=10).std();other_cores=[c for c in df.columns if 'cpu_util_core' in c and c != 'cpu_util_core_0'];\n",
    "    for i in range(1,6):\n",
    "        df_f[f'overall_util_lag_{i}']=df_f['cpu_util_overall'].shift(i)\n",
    "        for core in other_cores:df_f[f'{core}_lag_{i}']=df_f[core].shift(i)\n",
    "    return df_f.drop('workload_type',axis=1).dropna().reset_index(drop=True)\n",
    "def create_v2_3_features(df):\n",
    "    df_f=df.copy();workload_dummies=pd.get_dummies(df_f['workload_type'],prefix='workload');df_f=pd.concat([df_f,workload_dummies],axis=1);df_f['overall_util_rolling_mean']=df_f['cpu_util_overall'].rolling(window=30).mean();df_f['overall_util_rolling_std']=df_f['cpu_util_overall'].rolling(window=30).std();other_cores=[c for c in df.columns if 'cpu_util_core' in c and c != 'cpu_util_core_0'];\n",
    "    for i in range(1,21):\n",
    "        df_f[f'overall_util_lag_{i}']=df_f['cpu_util_overall'].shift(i)\n",
    "        if i<=10: \n",
    "            for core in other_cores:df_f[f'{core}_lag_{i}']=df_f[core].shift(i)\n",
    "    return df_f.drop('workload_type',axis=1).dropna().reset_index(drop=True)\n",
    "\n",
    "# --- Create and Align Feature Sets ---\n",
    "df_v2_0=create_v2_0_features(df);df_v2_3=create_v2_3_features(df);target='cpu_util_core_0';common_indices=df_v2_0.index.intersection(df_v2_3.index);df_aligned_v2_0=df_v2_0.loc[common_indices];df_aligned_v2_3=df_v2_3.loc[common_indices];\n",
    "features_v2_0_cols=[c for c in df_aligned_v2_0.columns if ('cpu_util' in c and c!=target) or 'workload_' in c];features_v2_3_cols=[c for c in df_aligned_v2_3.columns if ('cpu_util' in c and c!=target) or 'workload_' in c];\n",
    "X_v2_0=df_aligned_v2_0[features_v2_0_cols];X_v2_3=df_aligned_v2_3[features_v2_3_cols];y=df_aligned_v2_0[target];\n",
    "print(f\"Data aligned. Final dataset size: {len(y)} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a3c4af",
   "metadata": {},
   "source": [
    "### 2. Hierarchical Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01924a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Stage 1: Generating Layer 1 Predictions ---\n",
      "--- Stage 2: Training Layer 2 Meta-Models ---\n",
      "--- Stage 3: Training Layer 3 Superior AI ---\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 761\n",
      "[LightGBM] [Info] Number of data points in the train set: 5519, number of used features: 3\n",
      "--- Evaluating on hold-out test set ---\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 765\n",
      "[LightGBM] [Info] Number of data points in the train set: 5519, number of used features: 3\n",
      "[LightGBM] [Info] Start training from score 4.857456\n",
      "\n",
      "--- Final Hierarchical Ensemble Performance ---\n",
      "R-squared (R²): 0.6995\n",
      "\n",
      "LIMIT REACHED: The Deep Ensemble did not improve performance. The simpler V2.5 Stacking model remains the champion.\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(len(y))\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"--- Stage 1: Generating Layer 1 Predictions ---\")\n",
    "layer1_preds_train_v2_0 = cross_val_predict(model_v2_0, X_v2_0.iloc[train_indices], y.iloc[train_indices], cv=5, n_jobs=-1)\n",
    "layer1_preds_train_v2_1 = cross_val_predict(model_v2_1, X_v2_0.iloc[train_indices], y.iloc[train_indices], cv=5, n_jobs=-1)\n",
    "layer1_preds_train_v2_3 = cross_val_predict(model_v2_3, X_v2_3.iloc[train_indices], y.iloc[train_indices], cv=5, n_jobs=-1)\n",
    "X_meta_train_L2 = pd.DataFrame({'pred_v2_0': layer1_preds_train_v2_0, 'pred_v2_1': layer1_preds_train_v2_1, 'pred_v2_3': layer1_preds_train_v2_3})\n",
    "y_train_L2 = y.iloc[train_indices]\n",
    "\n",
    "print(\"--- Stage 2: Training Layer 2 Meta-Models ---\")\n",
    "meta_model_X = RidgeCV()\n",
    "meta_model_Y = lgb.LGBMRegressor(random_state=42, n_jobs=-1)\n",
    "meta_model_Z = KNeighborsRegressor(n_neighbors=10)\n",
    "layer2_preds_train_X = cross_val_predict(meta_model_X, X_meta_train_L2, y_train_L2, cv=5, n_jobs=-1)\n",
    "layer2_preds_train_Y = cross_val_predict(meta_model_Y, X_meta_train_L2, y_train_L2, cv=5, n_jobs=-1)\n",
    "layer2_preds_train_Z = cross_val_predict(meta_model_Z, X_meta_train_L2, y_train_L2, cv=5, n_jobs=-1)\n",
    "X_meta_train_L3 = pd.DataFrame({'pred_meta_X': layer2_preds_train_X, 'pred_meta_Y': layer2_preds_train_Y, 'pred_meta_Z': layer2_preds_train_Z})\n",
    "y_train_L3 = y_train_L2\n",
    "\n",
    "print(\"--- Stage 3: Training Layer 3 Superior AI ---\")\n",
    "superior_model = lgb.LGBMRegressor(**model_v2_3.get_params())\n",
    "superior_model.fit(X_meta_train_L3, y_train_L3)\n",
    "\n",
    "print(\"--- Evaluating on hold-out test set ---\")\n",
    "layer1_preds_test_v2_0=model_v2_0.predict(X_v2_0.iloc[test_indices]);layer1_preds_test_v2_1=model_v2_1.predict(X_v2_0.iloc[test_indices]);layer1_preds_test_v2_3=model_v2_3.predict(X_v2_3.iloc[test_indices]);\n",
    "X_meta_test_L2=pd.DataFrame({'pred_v2_0':layer1_preds_test_v2_0,'pred_v2_1':layer1_preds_test_v2_1,'pred_v2_3':layer1_preds_test_v2_3})\n",
    "meta_model_X.fit(X_meta_train_L2,y_train_L2);meta_model_Y.fit(X_meta_train_L2,y_train_L2);meta_model_Z.fit(X_meta_train_L2,y_train_L2);\n",
    "layer2_preds_test_X=meta_model_X.predict(X_meta_test_L2);layer2_preds_test_Y=meta_model_Y.predict(X_meta_test_L2);layer2_preds_test_Z=meta_model_Z.predict(X_meta_test_L2);\n",
    "X_meta_test_L3=pd.DataFrame({'pred_meta_X':layer2_preds_test_X,'pred_meta_Y':layer2_preds_test_Y,'pred_meta_Z':layer2_preds_test_Z})\n",
    "final_predictions=superior_model.predict(X_meta_test_L3)\n",
    "y_test=y.iloc[test_indices]\n",
    "r2 = r2_score(y_test, final_predictions)\n",
    "\n",
    "print(f\"\\n--- Final Hierarchical Ensemble Performance ---\")\n",
    "print(f\"R-squared (R²): {r2:.4f}\")\n",
    "\n",
    "if r2 >= 0.85:\n",
    "    print(\"\\nMISSION ACCOMPLISHED: The Deep Ensemble has broken the 85% barrier!\")\n",
    "elif r2 > 0.7436:\n",
    "    print(\"\\nULTIMATE BREAKTHROUGH: The Deep Ensemble is the new state-of-the-art.\")\n",
    "else:\n",
    "    print(\"\\nLIMIT REACHED: The Deep Ensemble did not improve performance. The simpler V2.5 Stacking model remains the champion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5b0f87-21fa-4570-8d2f-401bc241ff4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
