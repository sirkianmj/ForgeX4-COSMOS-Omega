{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07aa041c",
   "metadata": {},
   "source": [
    "# Digital Twin v2.2: Signal Processing Features\n",
    "\n",
    "**Author:** Kian Mansouri Jamshidi\n",
    "**Project Director:** Kian Mansouri Jamshidi\n",
    "**Date:** 2025-09-27\n",
    "\n",
    "## Objective\n",
    "Previous models have reached a performance plateau around R²=0.70. This indicates we need a more sophisticated feature representation. This notebook treats our telemetry data as a digital signal and applies advanced techniques from **Digital Signal Processing (DSP)** to extract \"smarter\" features.\n",
    "\n",
    "Our goal is to create features that describe the *dynamics and shape* of the CPU utilization signal, providing the model with higher-level insights. We will test if this superior feature space can finally break the performance barrier and approach our ultimate goal of **R² ≥ 0.85-0.90**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a43f33a",
   "metadata": {},
   "source": [
    "### 1. Imports and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a7b5b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded with 6928 total points.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "import pywt\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# --- Load and Prepare Data (Condensed) --- #\n",
    "PROJECT_ROOT = Path('.').resolve().parent\n",
    "TELEMETRY_DIR = PROJECT_ROOT / 'data' / 'telemetry_v2'\n",
    "ARTIFACT_DIR = PROJECT_ROOT / 'artifacts' / 'phase2'\n",
    "df_list = [pd.read_parquet(file) for file in glob.glob(str(TELEMETRY_DIR / \"*.parquet\"))]\n",
    "df = pd.concat(df_list, ignore_index=True).sort_values(by='timestamp').reset_index(drop=True)\n",
    "print(f\"Data loaded with {len(df)} total points.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d32024",
   "metadata": {},
   "source": [
    "### 2. DSP Feature Engineering Function\n",
    "\n",
    "We will define a function that takes a window of signal data (e.g., the last 20 CPU utilization readings) and computes our advanced DSP features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc6b5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSP feature function defined.\n"
     ]
    }
   ],
   "source": [
    "def get_dsp_features(window_data):\n",
    "    features = {}\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    signal = window_data.to_numpy()\n",
    "    \n",
    "    # --- FFT Features ---\n",
    "    N = len(signal)\n",
    "    if N > 1:\n",
    "        yf = np.abs(rfft(signal))\n",
    "        xf = rfftfreq(N, 1 / 10) # Assuming 10Hz sample rate\n",
    "        features['fft_dominant_freq'] = xf[np.argmax(yf[1:])+1] if len(yf) > 1 else 0\n",
    "        features['fft_power_mean'] = np.mean(yf)\n",
    "        features['fft_power_std'] = np.std(yf)\n",
    "    else:\n",
    "        features['fft_dominant_freq'] = 0\n",
    "        features['fft_power_mean'] = 0\n",
    "        features['fft_power_std'] = 0\n",
    "        \n",
    "    # --- Wavelet Features ---\n",
    "    if N > 4:\n",
    "        (cA, cD) = pywt.dwt(signal, 'db1')\n",
    "        features['wavelet_cA_mean'] = np.mean(cA)\n",
    "        features['wavelet_cA_std'] = np.std(cA)\n",
    "        features['wavelet_cD_mean'] = np.mean(cD)\n",
    "        features['wavelet_cD_std'] = np.std(cD)\n",
    "    else:\n",
    "        features['wavelet_cA_mean'] = 0\n",
    "        features['wavelet_cA_std'] = 0\n",
    "        features['wavelet_cD_mean'] = 0\n",
    "        features['wavelet_cD_std'] = 0\n",
    "        \n",
    "    # --- Signal Statistics ---\n",
    "    features['zero_crossing_rate'] = np.sum(np.diff(np.sign(signal - np.mean(signal))) != 0) / (2 * N)\n",
    "    \n",
    "    return pd.Series(features)\n",
    "\n",
    "print(\"DSP feature function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8770a4e",
   "metadata": {},
   "source": [
    "### 3. Applying Features and Building the Final DataFrame\n",
    "\n",
    "We will now apply this function to a rolling window of our CPU data. This is a computationally intensive step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15fccab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting advanced feature engineering...\n",
      "Feature engineering complete. Training set size: 5523\n",
      "Total DSP & Lag features: 18\n"
     ]
    }
   ],
   "source": [
    "# FINAL ADVANCED FEATURE ENGINEERING CELL (V4 - DEFINITIVE)\n",
    "\n",
    "print(\"Starting advanced feature engineering...\")\n",
    "WINDOW_SIZE = 20\n",
    "\n",
    "# --- THE FIX IS HERE: Drop the empty temperature column immediately after loading ---\n",
    "if 'cpu_temp_celsius_avg' in df.columns:\n",
    "    df = df.drop('cpu_temp_celsius_avg', axis=1)\n",
    "\n",
    "# --- 1. Calculate DSP features ---\n",
    "dsp_feature_list = []\n",
    "for i in range(len(df) - WINDOW_SIZE + 1):\n",
    "    window = df['cpu_util_overall'].iloc[i : i + WINDOW_SIZE]\n",
    "    dsp_features = get_dsp_features(window)\n",
    "    dsp_feature_list.append(dsp_features)\n",
    "dsp_features_df = pd.DataFrame(dsp_feature_list)\n",
    "\n",
    "# --- 2. Prepare the base DataFrame ---\n",
    "df_base = df.iloc[WINDOW_SIZE - 1:].reset_index(drop=True)\n",
    "\n",
    "# --- 3. Create other features on this aligned base DataFrame ---\n",
    "df_featured = df_base.copy()\n",
    "workload_dummies = pd.get_dummies(df_featured['workload_type'], prefix='workload')\n",
    "df_featured = pd.concat([df_featured, workload_dummies], axis=1)\n",
    "for i in range(1, 6):\n",
    "    df_featured[f'overall_util_lag_{i}'] = df_featured['cpu_util_overall'].shift(i)\n",
    "\n",
    "# --- 4. Combine all features and clean up ---\n",
    "df_combined = pd.concat([df_featured, dsp_features_df], axis=1)\n",
    "df_model = df_combined.drop('workload_type', axis=1).dropna().reset_index(drop=True)\n",
    "\n",
    "# --- 5. Define Final X and y ---\n",
    "target = 'cpu_util_core_0'\n",
    "dsp_feature_names = list(dsp_features_df.columns)\n",
    "workload_feature_names = [col for col in df_model.columns if 'workload_' in col]\n",
    "lag_feature_names = [col for col in df_model.columns if 'lag' in col]\n",
    "features = dsp_feature_names + workload_feature_names + lag_feature_names\n",
    "\n",
    "X = df_model[features]\n",
    "y = df_model[target]\n",
    "\n",
    "if len(X) == 0:\n",
    "    raise ValueError(\"The final DataFrame is empty after feature engineering! Halting.\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Feature engineering complete. Training set size: {len(X_train)}\")\n",
    "print(f\"Total DSP & Lag features: {len(features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63ccc10",
   "metadata": {},
   "source": [
    "### 4. Train the Final Model\n",
    "\n",
    "We will use our best-performing algorithm, LightGBM, with the parameters we found during the tuning phase. We are now testing if a \"smarter\" feature set can elevate the performance of our best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85e76ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final DSP-featured LightGBM model...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2137\n",
      "[LightGBM] [Info] Number of data points in the train set: 5523, number of used features: 18\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's l1: 4.24771\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# Using the best parameters from our previous tuning run\n",
    "best_params = {\n",
    "    'objective': 'regression_l1',\n",
    "    'n_estimators': 1500,\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 40,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "model = lgb.LGBMRegressor(**best_params)\n",
    "\n",
    "print(\"Training final DSP-featured LightGBM model...\")\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric='r2',\n",
    "    callbacks=[lgb.early_stopping(100, verbose=True)]\n",
    ")\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac8a5d2",
   "metadata": {},
   "source": [
    "### 5. Final Evaluation\n",
    "\n",
    "This is the final test. Will the signal processing features allow our model to break through the performance ceiling?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb9d5475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Final DSP Model Performance ---\n",
      "R-squared (R²): 0.0077\n",
      "\n",
      "STABLE: The DSP features did not yield a significant improvement over the previous best model.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"--- Final DSP Model Performance ---\")\n",
    "print(f\"R-squared (R²): {r2:.4f}\")\n",
    "\n",
    "if r2 >= 0.85:\n",
    "    print(\"\\nMISSION ACCOMPLISHED: Performance has broken the 85% barrier!\")\n",
    "elif r2 > 0.71:\n",
    "    print(\"\\nSIGNIFICANT IMPROVEMENT: The DSP features provided a clear performance boost.\")\n",
    "else:\n",
    "    print(\"\\nSTABLE: The DSP features did not yield a significant improvement over the previous best model.\")\n",
    "\n",
    "# Save the artifact if it's our best model yet\n",
    "if r2 > 0.71:\n",
    "    model_path = ARTIFACT_DIR / 'digital_twin_v2.2_dsp.joblib'\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"New best model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df80111a-e24e-49dc-a9c8-cc74f007fe5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
