{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d57327a2",
   "metadata": {},
   "source": [
    "# Digital Twin v2.3: Deep History Model\n",
    "\n",
    "**Author:** Kian Mansouri Jamshidi\n",
    "**Project Director:** Kian Mansouri Jamshidi\n",
    "**Date:** 2025-09-27\n",
    "\n",
    "## Objective\n",
    "This notebook is our final attempt to maximize the performance of our Digital Twin. Building on the success of the V2 model (R² ≈ 0.71), we will test the hypothesis that a more powerful model can be trained by providing it with a **deeper historical context** and configuring the LightGBM algorithm for **maximum learning capacity**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b93610",
   "metadata": {},
   "source": [
    "### 1. Imports and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4117e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded with 6928 total points.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# --- Load Data ---\n",
    "PROJECT_ROOT = Path('.').resolve().parent\n",
    "TELEMETRY_DIR = PROJECT_ROOT / 'data' / 'telemetry_v2'\n",
    "ARTIFACT_DIR = PROJECT_ROOT / 'artifacts' / 'phase2'\n",
    "df_list = [pd.read_parquet(file) for file in glob.glob(str(TELEMETRY_DIR / \"*.parquet\"))]\n",
    "df = pd.concat(df_list, ignore_index=True).sort_values(by='timestamp').reset_index(drop=True)\n",
    "if 'cpu_temp_celsius_avg' in df.columns:\n",
    "    df = df.drop('cpu_temp_celsius_avg', axis=1)\n",
    "print(f\"Data loaded with {len(df)} total points.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6302e90e",
   "metadata": {},
   "source": [
    "### 2. Deep Feature Engineering\n",
    "\n",
    "We will significantly increase the window and lag sizes to give the model a much longer-term memory of system behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "040028ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using WINDOW_SIZE=30 and LAG_AMOUNT=20\n",
      "Feature engineering complete. Training set size: 5519\n",
      "Total deep features: 83\n"
     ]
    }
   ],
   "source": [
    "# --- DEEPER HISTORY PARAMETERS --- #\n",
    "WINDOW_SIZE = 30 # Approx 3 seconds of history for rolling stats\n",
    "LAG_AMOUNT = 20  # Approx 2 seconds of history for lag features\n",
    "\n",
    "print(f\"Using WINDOW_SIZE={WINDOW_SIZE} and LAG_AMOUNT={LAG_AMOUNT}\")\n",
    "\n",
    "df_featured = df.copy()\n",
    "workload_dummies = pd.get_dummies(df_featured['workload_type'], prefix='workload')\n",
    "df_featured = pd.concat([df_featured, workload_dummies], axis=1)\n",
    "\n",
    "df_featured['overall_util_rolling_mean'] = df_featured['cpu_util_overall'].rolling(window=WINDOW_SIZE).mean()\n",
    "df_featured['overall_util_rolling_std'] = df_featured['cpu_util_overall'].rolling(window=WINDOW_SIZE).std()\n",
    "\n",
    "other_core_cols = [col for col in df.columns if 'cpu_util_core' in col and col != 'cpu_util_core_0']\n",
    "for i in range(1, LAG_AMOUNT + 1):\n",
    "    df_featured[f'overall_util_lag_{i}'] = df_featured['cpu_util_overall'].shift(i)\n",
    "    # We will only lag the *other* cores for a shorter period to keep the feature count manageable\n",
    "    if i <= 10:\n",
    "        for core_col in other_core_cols:\n",
    "            df_featured[f'{core_col}_lag_{i}'] = df_featured[core_col].shift(i)\n",
    "\n",
    "df_model = df_featured.drop('workload_type', axis=1).dropna().reset_index(drop=True)\n",
    "\n",
    "target = 'cpu_util_core_0'\n",
    "features = [col for col in df_model.columns if ('cpu_util' in col and col != target) or 'workload_' in col]\n",
    "\n",
    "X = df_model[features]\n",
    "y = df_model[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Feature engineering complete. Training set size: {len(X_train)}\")\n",
    "print(f\"Total deep features: {len(features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311a79a6",
   "metadata": {},
   "source": [
    "### 3. Train High-Capacity Model\n",
    "\n",
    "We will now train a LightGBM model configured for higher accuracy and learning capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1cbd11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final Deep History LightGBM model...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2230\n",
      "[LightGBM] [Info] Number of data points in the train set: 5519, number of used features: 83\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1975]\tvalid_0's l1: 2.79353\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# --- HIGH-CAPACITY MODEL PARAMETERS --- #\n",
    "deep_params = {\n",
    "    'objective': 'regression_l1',\n",
    "    'n_estimators': 2000,        # More trees\n",
    "    'learning_rate': 0.01,       # Slower learning\n",
    "    'num_leaves': 50,            # More complex trees\n",
    "    'colsample_bytree': 0.7,\n",
    "    'subsample': 0.7,            # Add data subsampling for robustness\n",
    "    'reg_alpha': 0.1,            # L1 regularization\n",
    "    'reg_lambda': 0.1,           # L2 regularization\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "model = lgb.LGBMRegressor(**deep_params)\n",
    "\n",
    "print(\"Training final Deep History LightGBM model...\")\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric='r2',\n",
    "    callbacks=[lgb.early_stopping(100, verbose=True)]\n",
    ")\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc3dfc",
   "metadata": {},
   "source": [
    "### 4. Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eccad253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Final Deep Model Performance ---\n",
      "R-squared (R²): 0.6979\n",
      "\n",
      "LIMIT REACHED: The deep history features did not improve performance. V2.0 remains the champion.\n",
      "\n",
      "Deep model saved for ensemble experiment to: /home/kian/Desktop/ForgeX4-COSMOS-Omega/artifacts/phase2/digital_twin_v2.3_deep.joblib\n"
     ]
    }
   ],
   "source": [
    "# FINAL EVALUATION CELL (CORRECTED TO ALWAYS SAVE)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"--- Final Deep Model Performance ---\")\n",
    "print(f\"R-squared (R²): {r2:.4f}\")\n",
    "\n",
    "if r2 >= 0.85:\n",
    "    print(\"\\nMISSION ACCOMPLISHED: Performance has broken the 85% barrier!\")\n",
    "elif r2 > 0.71:\n",
    "    print(\"\\nBREAKTHROUGH: The deep history features provided a significant performance boost.\")\n",
    "else:\n",
    "    print(\"\\nLIMIT REACHED: The deep history features did not improve performance. V2.0 remains the champion.\")\n",
    "\n",
    "# --- THE FIX IS HERE: We will now save the model regardless of the score ---\n",
    "model_path = ARTIFACT_DIR / 'digital_twin_v2.3_deep.joblib'\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"\\nDeep model saved for ensemble experiment to: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0033a075-3f1d-4efc-ba2a-e3effef331d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
